{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d636973d-c27d-493e-8a27-d532bff1d90c",
   "metadata": {},
   "source": "## Assignment Week 3 - grk"
  },
  {
   "cell_type": "markdown",
   "id": "20d4b374-45a0-4676-a8c9-db16b182c84f",
   "metadata": {},
   "source": [
    "#### Part 1: Using the TextBlob Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "id": "d81ec862-79de-465f-ae55-ca8f38a81d6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T21:28:20.617624Z",
     "start_time": "2025-02-08T21:28:20.607063Z"
    }
   },
   "source": [
    "# import modules\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "51d0316e-04fb-4320-9295-dff5497a27b3",
   "metadata": {},
   "source": [
    "Import the movie review data as a data frame and ensure that the data is loaded properly."
   ]
  },
  {
   "cell_type": "code",
   "id": "65ba9545-c63c-44a8-b79e-7fab4055c415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T21:28:21.096153Z",
     "start_time": "2025-02-08T21:28:20.702901Z"
    }
   },
   "source": [
    "# read the dataset as a dataframe\n",
    "df = pd.read_csv(\"./assignments-data/labeledTrainData.tsv\", sep=\"\\t\")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "ce00e355-0f51-4718-8c93-2297232067e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T21:28:21.107209Z",
     "start_time": "2025-02-08T21:28:21.098172Z"
    }
   },
   "source": [
    "# view few rows to check dataset is loaded correcly\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "4200a859-bbc3-4acb-b342-bfbce605e929",
   "metadata": {},
   "source": [
    "How many of each positive and negative reviews are there?"
   ]
  },
  {
   "cell_type": "code",
   "id": "f0a4f451-aa19-4a82-a8a2-93cd97f02786",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T21:28:21.115643Z",
     "start_time": "2025-02-08T21:28:21.107209Z"
    }
   },
   "source": [
    "# using value counts to get counts of postive and negetive sentiments\n",
    "df[\"sentiment\"].value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    12500\n",
       "0    12500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "5422f512-d8a0-4afc-ab93-1cdaff5cb0f8",
   "metadata": {},
   "source": [
    "Use TextBlob to classify each movie review as positive or negative. Assume that a polarity score greater than or equal to zero is a positive sentiment and less than 0 is a negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "id": "60f63d39-d3e4-47ed-9c43-f5e8e80973fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T21:28:21.122572Z",
     "start_time": "2025-02-08T21:28:21.117160Z"
    }
   },
   "source": [
    "# this function converts input text to lower case and then performs sentiment analysis using TextBlob sentiment analyzer\n",
    "# this function returns 1 (positive) if polarity of TextBlob sentiment analysis is greater than 0 otherwise returns 0 (negative)\n",
    "def perform_sentiment_analysis(text):\n",
    "    testimonial = TextBlob(text.lower())\n",
    "    return 0 if testimonial.sentiment.polarity < 0 else 1"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "9ebf2ee1-b4d7-4ac2-bf94-47886bb6eb2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T21:28:27.088696Z",
     "start_time": "2025-02-08T21:28:21.122572Z"
    }
   },
   "source": [
    "# perform sentiment analysis for each review and store in a new column\n",
    "df[\"textblob_sentiment\"] = df[\"review\"].apply(perform_sentiment_analysis)"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# perform sentiment analysis for each review and store in a new column\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtextblob_sentiment\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreview\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mperform_sentiment_analysis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[0;32m   4789\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4790\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4791\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4796\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4797\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4798\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4799\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4800\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4915\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4916\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   4917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4918\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4920\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4922\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m-> 4924\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[0;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[1;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[0;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[0;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[0;32m   1509\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[1;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[1;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[0;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[0;32m   1747\u001B[0m     )\n",
      "File \u001B[1;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[17], line 5\u001B[0m, in \u001B[0;36mperform_sentiment_analysis\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mperform_sentiment_analysis\u001B[39m(text):\n\u001B[0;32m      4\u001B[0m     testimonial \u001B[38;5;241m=\u001B[39m TextBlob(text\u001B[38;5;241m.\u001B[39mlower())\n\u001B[1;32m----> 5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mtestimonial\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msentiment\u001B[49m\u001B[38;5;241m.\u001B[39mpolarity \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\textblob\\decorators.py:23\u001B[0m, in \u001B[0;36mcached_property.__get__\u001B[1;34m(self, obj, cls)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\u001B[1;32m---> 23\u001B[0m value \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m value\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\textblob\\blob.py:439\u001B[0m, in \u001B[0;36mBaseBlob.sentiment\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    430\u001B[0m \u001B[38;5;129m@cached_property\u001B[39m\n\u001B[0;32m    431\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msentiment\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    432\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return a tuple of form (polarity, subjectivity ) where polarity\u001B[39;00m\n\u001B[0;32m    433\u001B[0m \u001B[38;5;124;03m    is a float within the range [-1.0, 1.0] and subjectivity is a float\u001B[39;00m\n\u001B[0;32m    434\u001B[0m \u001B[38;5;124;03m    within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;124;03m    :rtype: namedtuple of the form ``Sentiment(polarity, subjectivity)``\u001B[39;00m\n\u001B[0;32m    438\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manalyzer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manalyze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\textblob\\en\\sentiments.py:45\u001B[0m, in \u001B[0;36mPatternAnalyzer.analyze\u001B[1;34m(self, text, keep_assessments)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     44\u001B[0m     Sentiment \u001B[38;5;241m=\u001B[39m namedtuple(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSentiment\u001B[39m\u001B[38;5;124m\"\u001B[39m, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpolarity\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msubjectivity\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Sentiment(\u001B[38;5;241m*\u001B[39m\u001B[43mpattern_sentiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\textblob\\_text.py:1000\u001B[0m, in \u001B[0;36mSentiment.__call__\u001B[1;34m(self, s, negation, **kwargs)\u001B[0m\n\u001B[0;32m    997\u001B[0m \u001B[38;5;66;03m# A string of words.\u001B[39;00m\n\u001B[0;32m    998\u001B[0m \u001B[38;5;66;03m# Sentiment(\"a horrible movie\") => (-0.6, 1.0)\u001B[39;00m\n\u001B[0;32m    999\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(s, basestring):\n\u001B[1;32m-> 1000\u001B[0m     a \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massessments\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1001\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1002\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnegation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1003\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1004\u001B[0m \u001B[38;5;66;03m# A pattern.en.Text.\u001B[39;00m\n\u001B[0;32m   1005\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(s, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentences\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\gyan-python-workspace\\jup-workspace\\venv\\Lib\\site-packages\\textblob\\_text.py:1087\u001B[0m, in \u001B[0;36mSentiment.assessments\u001B[1;34m(self, words, negation)\u001B[0m\n\u001B[0;32m   1082\u001B[0m m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1083\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1084\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1085\u001B[0m     pos\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m pos \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodifiers\n\u001B[1;32m-> 1087\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;43many\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mw\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__contains__\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodifiers\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1088\u001B[0m ):\n\u001B[0;32m   1089\u001B[0m     m \u001B[38;5;241m=\u001B[39m (w, pos)\n\u001B[0;32m   1090\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m negation \u001B[38;5;129;01mand\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnegations:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "25784ac9-5255-4023-8c37-542b711ab26c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T21:28:27.088696Z",
     "start_time": "2025-02-08T21:28:27.088696Z"
    }
   },
   "source": [
    "# view few rows\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "38132f9c-9a40-4fec-b980-b1fe72def70b",
   "metadata": {},
   "source": [
    "Check the accuracy of this model. Is this model better than random guessing?"
   ]
  },
  {
   "cell_type": "code",
   "id": "e977363b-871f-4d87-9529-cf230e239bb6",
   "metadata": {},
   "source": [
    "# importing accuracy score module for calculating accuracy\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eadedb05-978b-435d-9934-5e23e0f3694e",
   "metadata": {},
   "source": [
    "# get accuracy score for sentiment generated by TextBlob against the labeled data\n",
    "accuracy_score(df[\"sentiment\"],df[\"textblob_sentiment\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4b1038f1-2e68-48ca-a900-64133bbe49b8",
   "metadata": {},
   "source": [
    "The sentiment analyzer model using `TextBlob` has an accuracy of $68.5$%. The original labeleled dataset has has $50$% positive and $50$% negetive sentiment. Hence, with random guessing we can expect to get a maximum of $50$% accuracy. However, the `TextBlob` sentiment analyzer model has accuracy higher than the $50$%, therefore we can say that the `TextBlob` model is better than _random guessing_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda02db9-931a-42fb-ae8b-12dd128257ad",
   "metadata": {},
   "source": [
    "For up to five points extra credit, use another prebuilt text sentiment analyzer, e.g., VADER, and repeat steps (3) and (4)."
   ]
  },
  {
   "cell_type": "code",
   "id": "d9d31e8a-dc78-480e-bdb2-5f3ef28fafa0",
   "metadata": {},
   "source": [
    "# import VADER sentiment analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3aa0b6d-8bbe-49e1-b5a9-e491bac1a897",
   "metadata": {},
   "source": [
    "# this function performs VADER sentiment analysis on the input text and returns 1 (poitive) \n",
    "# if the compound score from the analysis is greater than eqaul 0 otherwise 0 (negative)\n",
    "def perform_sentiment_analysis_using_vader(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment_dict = analyzer.polarity_scores(text.lower())\n",
    "    return 0 if sentiment_dict[\"compound\"] < 0 else 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "29058de4-2b8c-47aa-9a74-1c979525ee8a",
   "metadata": {},
   "source": [
    "# perform VADER sentiment analysis for each review using above function and store in a new column\n",
    "df[\"sentiment_with_vader\"] = df[\"review\"].apply(perform_sentiment_analysis_using_vader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eda420f0-9dec-4234-9acc-0e9846d541fa",
   "metadata": {},
   "source": [
    "# view few rows\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e88a40ff-e823-48a7-90c3-75020c92e8fd",
   "metadata": {},
   "source": [
    "# get accuracy score for sentiment generated by VADER against the labeled data\n",
    "accuracy_score(df[\"sentiment\"],df[\"sentiment_with_vader\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "01c07cee-d2c0-48b4-9529-feda55210793",
   "metadata": {},
   "source": [
    "We see that the accuracy of _Sentiment analysis_ using `VADER` sentiment analyzer did not change much from `TextBlob` sentiment analyzer, just $1$% increase in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eca1611-8171-413a-9c95-c7215c020393",
   "metadata": {},
   "source": [
    "#### Part 2: Prepping Text for a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "192ad05b-9f6a-487c-936c-11cd2c15be0d",
   "metadata": {},
   "source": [
    "# import modules\n",
    "\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a5e3bef1-2537-4e4b-8134-fbdc9c612224",
   "metadata": {},
   "source": [
    "# read the dataset into a dataframe\n",
    "df = pd.read_csv(\"./datasets/labeledTrainData.tsv\", sep=\"\\t\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa77082e-eed0-41fa-bbd9-c491a82e64cf",
   "metadata": {},
   "source": [
    "Convert all text to lowercase letters."
   ]
  },
  {
   "cell_type": "code",
   "id": "5b13c89e-4306-4173-bdd2-919df6465ee3",
   "metadata": {},
   "source": [
    "# convert reviews to lower case and store in a new column\n",
    "df[\"cleaned_review\"] = df[\"review\"].str.lower()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b83d702c-895d-4439-87b9-62842e8b3499",
   "metadata": {},
   "source": [
    "Remove punctuation and special characters from the text."
   ]
  },
  {
   "cell_type": "code",
   "id": "5ff11a9e-7c24-49b0-a3e9-2ba9af812738",
   "metadata": {},
   "source": [
    "# this function clean punctuation and symbols from input text\n",
    "punctuation = dict.fromkeys(\n",
    "[i for i in range(sys.maxunicode)\n",
    "if unicodedata.category(chr(i)).startswith(\"P\") or unicodedata.category(chr(i)).startswith(\"S\")],\n",
    "    None\n",
    " )\n",
    "def remove_punctuation_symbols(text):\n",
    "    return text.translate(punctuation)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "411155bb-7fbe-4c81-bef9-9594038aa417",
   "metadata": {},
   "source": [
    "# remove punctuation and symbols from reviews using the above function \n",
    "df[\"cleaned_review\"] = df[\"cleaned_review\"].apply(remove_punctuation_symbols)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b46098d-ab58-445b-b455-90dba3983981",
   "metadata": {},
   "source": [
    "# this function removes stopwords from input text\n",
    "stop_words = stopwords.words(\"english\")\n",
    "def remove_stopwords(text):\n",
    "    tokenized_words = word_tokenize(text)\n",
    "    return \" \".join([word for word in tokenized_words if word not in stop_words])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f01ba4c7-3827-4595-9cf4-478812c7d3d4",
   "metadata": {},
   "source": [
    "Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "id": "ccfae8d2-4e70-444a-8779-d2ef14a63e97",
   "metadata": {},
   "source": [
    "# remove stopwords from reviews using above function\n",
    "df[\"cleaned_review\"] = df[\"cleaned_review\"].apply(remove_stopwords)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5ee850ec-09ac-4930-9351-e5642fab874e",
   "metadata": {},
   "source": [
    "Apply NLTKâ€™s PorterStemmer."
   ]
  },
  {
   "cell_type": "code",
   "id": "2733f00a-d107-4994-85ff-cdcd220b993b",
   "metadata": {},
   "source": [
    "# this function perform stemming on the input text using NLTK PorterStemmer\n",
    "def porter_stemmer(text):\n",
    "    tokenized_words = word_tokenize(text)\n",
    "    porter = PorterStemmer()\n",
    "    return \" \".join([porter.stem(words) for words in tokenized_words])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7a13c690-bac8-4f73-8db8-73dc029fb20d",
   "metadata": {},
   "source": [
    "# apply stemming on reviews using above function\n",
    "df[\"cleaned_review\"] = df[\"cleaned_review\"].apply(porter_stemmer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc493a53-dea9-4751-a9bb-6d1ad4df3071",
   "metadata": {},
   "source": [
    "# view few rows after the above text preparation\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f4b0292b-0735-46a2-b85a-4c45c60aece1",
   "metadata": {},
   "source": [
    "Create a bag-of-words matrix from your stemmed text (output from (4)), where each row is a word-count vector for a single movie review (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook). Display the dimensions of your bag-of-words matrix. The number of rows in this matrix should be the same as the number of rows in your original data frame."
   ]
  },
  {
   "cell_type": "code",
   "id": "3d80db33-ba1e-480e-b09a-f7ba3669767e",
   "metadata": {},
   "source": [
    "# Generate bag of words matrix using CountVectorizer\n",
    "count_vec = CountVectorizer()\n",
    "bag_of_words = count_vec.fit_transform(df[\"cleaned_review\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "695cd9de-3efb-4967-9bac-b39830cb49ea",
   "metadata": {},
   "source": [
    "# dimensions of the generated bag-of-words matrix\n",
    "bag_of_words.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c89568ee-86b2-4af5-bb6b-ba08541d66f9",
   "metadata": {},
   "source": [
    "# dimensions of the dataframe\n",
    "df.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0bb54890-f7b9-4406-90d5-08e39c92f722",
   "metadata": {},
   "source": [
    "we see that the number of rows of the bag-of-words matrix is same as the number of rows in the original dataframe i.e $25000$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a50c5-3624-4da1-aea2-3e231f603932",
   "metadata": {},
   "source": [
    "Create a term frequency-inverse document frequency (tf-idf) matrix from your stemmed text, for your movie reviews (see section 6.9 in the Machine Learning with Python Cookbook). Display the dimensions of your tf-idf matrix. These dimensions should be the same as your bag-of-words matrix"
   ]
  },
  {
   "cell_type": "code",
   "id": "cc829b28-b002-4008-a11b-e7174a12de4c",
   "metadata": {},
   "source": [
    "# generate term frequency-inverse document frequency (tf-idf) matrix using TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_feature_matrix = tfidf.fit_transform(df[\"cleaned_review\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c45ce101-44a6-432e-b2cd-43ebf2cb171a",
   "metadata": {},
   "source": [
    "# dimensions of te tf-idf feature matrix\n",
    "tfidf_feature_matrix.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "10eaefaa-d4d8-468b-9e71-ceac135fcb1f",
   "metadata": {},
   "source": [
    "we see that the number of rows of the tf-idf matrix is same as the number of rows in the original dataframe i.e.$25000$"
   ]
  },
  {
   "cell_type": "code",
   "id": "1b064442-3f3e-4511-b633-aacd68d25b7f",
   "metadata": {},
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "24dd887d-dac1-4c26-ad6b-464485c83915",
   "metadata": {},
   "source": [
    "df[(df[\"sentiment\"] == 1) & (df[\"textblob_sentiment\"] == 1)].shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce234eec-9f4d-4bbd-9b05-a77064ee7c92",
   "metadata": {},
   "source": [
    "df[(df[\"sentiment\"] == 0) & (df[\"textblob_sentiment\"] == 1)].shape"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
